{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is scikit-learn (sklearn)?\n",
    "* It's a machine learning package for python.\n",
    "* It's built on numpy, scipy and matplotlib.\n",
    "    * It's fast and efficient.\n",
    "    * It prefers working with arrays.\n",
    "* Advantages:\n",
    "    * Incredible documentations\n",
    "    * Variety\n",
    "        * Regression\n",
    "        * Classification\n",
    "        * Clustering\n",
    "        * Support vector machines\n",
    "        * Dimensionality reduction\n",
    "    * Numerical stability\n",
    "* Disadvantages: Deep learning where there are much better packages like tensorflow, keras and pytorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA\n",
       "0  1714  2.40\n",
       "1  1664  2.52\n",
       "2  1760  2.54\n",
       "3  1685  2.74\n",
       "4  1693  2.83"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('8.2 1.01. Simple linear regression.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84,), (84,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare dependent and independent Variables\n",
    "# in supervied-learning we're dealing with futures and targets\n",
    "x = data['SAT'] # input(feature)\n",
    "y = data['GPA'] # output(target)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn doesn't work with 1D models\n",
    "# so we should reshape our dataframe to a matrix\n",
    "x_matrix = x.values.reshape(-1, 1)\n",
    "x_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression itself\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40600391479679765"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-squared\n",
    "reg.score(x_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00165569])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficient\n",
    "reg.coef_ # this results in an array and in multiple regression models there is other coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27504029966028076"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.15593751])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions\n",
    "reg.predict(np.array(1740).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      SAT   GPA  Rand 1,2,3\n",
       "0   1714  2.40           1\n",
       "1   1664  2.52           3\n",
       "2   1760  2.54           3\n",
       "3   1685  2.74           3\n",
       "4   1693  2.83           2\n",
       "..   ...   ...         ...\n",
       "79  1936  3.71           3\n",
       "80  1810  3.71           1\n",
       "81  1987  3.73           3\n",
       "82  1962  3.76           1\n",
       "83  2050  3.81           2\n",
       "\n",
       "[84 rows x 3 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "data = pd.read_csv('3.2 1.02. Multiple linear regression.csv')\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dependent and independent variables\n",
    "y = data['GPA']\n",
    "x = data[['SAT', 'Rand 1,2,3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a multiple regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4066811952814283, array([ 0.00165354, -0.00826982]), 0.29603261264909486)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x, y), reg.coef_, reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Formula for Adj R-squared:\n",
    "* $R^2_{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3920313482513401"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = reg.score(x, y)\n",
    "n = x.shape[0]\n",
    "p = x.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature selection simplifies models by removing unneeded variables.\n",
    "    * This process improves speed and prevents a series of unwanted issues arising from having too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56.04804786,  0.17558437]), array([7.19951844e-11, 6.76291372e-01]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection with sklearn\n",
    "from sklearn.feature_selection import f_regression\n",
    "f_regression(x, y)\n",
    "# this will create two arrays:\n",
    "# the first contains f-statistics for each of the regressions\n",
    "# the second corresponding p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56.048,  0.176]), array([0.   , 0.676]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_statistics = f_regression(x, y)[0]\n",
    "p_values = f_regression(x, y)[1]\n",
    "f_statistics.round(3), p_values.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features\n",
       "0         SAT\n",
       "1  Rand 1,2,3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary = pd.DataFrame(data=x.columns.values, columns=['Features'])\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>p_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  coefficients  p_values\n",
       "0         SAT      0.001654     0.000\n",
       "1  Rand 1,2,3     -0.008270     0.676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary['coefficients'] = reg.coef_\n",
    "reg_summary['p_values'] = p_values.round(3)\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling (standardization)\n",
    "* The common problem when working with numeric data is difference in magnitudes.\n",
    "    * An easy fix for this issue is standardization. (feature scaling)\n",
    "        * Standardization is the process of transforming the data we're working with into a standard scale.\n",
    "        * (x-mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant module and creating an object\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x) # fit calculates and stores the standard deviation of each feature\n",
    "# scaler contains all standardization info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26338288, -1.24637147],\n",
       "       [-1.74458431,  1.10632974],\n",
       "       [-0.82067757,  1.10632974],\n",
       "       [-1.54247971,  1.10632974],\n",
       "       [-1.46548748, -0.07002087],\n",
       "       [-1.68684014, -1.24637147],\n",
       "       [-0.78218146, -0.07002087],\n",
       "       [-0.78218146, -1.24637147],\n",
       "       [-0.51270866, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [-1.06127829,  1.10632974],\n",
       "       [-0.67631715, -0.07002087],\n",
       "       [-1.06127829, -1.24637147],\n",
       "       [-1.28263094,  1.10632974],\n",
       "       [-0.6955652 , -0.07002087],\n",
       "       [ 0.25721362, -0.07002087],\n",
       "       [-0.86879772,  1.10632974],\n",
       "       [-1.64834403, -0.07002087],\n",
       "       [-0.03150724,  1.10632974],\n",
       "       [-0.57045283,  1.10632974],\n",
       "       [-0.81105355,  1.10632974],\n",
       "       [-1.18639066,  1.10632974],\n",
       "       [-1.75420834,  1.10632974],\n",
       "       [-1.52323165, -1.24637147],\n",
       "       [ 1.23886453, -1.24637147],\n",
       "       [-0.18549169, -1.24637147],\n",
       "       [-0.5608288 , -1.24637147],\n",
       "       [-0.23361183,  1.10632974],\n",
       "       [ 1.68156984, -1.24637147],\n",
       "       [-0.4934606 , -0.07002087],\n",
       "       [-0.73406132, -1.24637147],\n",
       "       [ 0.85390339, -1.24637147],\n",
       "       [-0.67631715, -1.24637147],\n",
       "       [ 0.09360513,  1.10632974],\n",
       "       [ 0.33420585, -0.07002087],\n",
       "       [ 0.03586096, -0.07002087],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 1.04638396,  1.10632974],\n",
       "       [-0.65706909,  1.10632974],\n",
       "       [-0.13737155, -0.07002087],\n",
       "       [ 0.18984542,  1.10632974],\n",
       "       [ 0.04548499, -1.24637147],\n",
       "       [ 1.1618723 ,  1.10632974],\n",
       "       [-1.37887123, -1.24637147],\n",
       "       [ 1.39284898, -1.24637147],\n",
       "       [ 0.76728713, -0.07002087],\n",
       "       [-0.20473975, -0.07002087],\n",
       "       [ 1.06563201, -1.24637147],\n",
       "       [ 0.11285319, -1.24637147],\n",
       "       [ 1.28698467,  1.10632974],\n",
       "       [-0.41646838,  1.10632974],\n",
       "       [ 0.09360513, -1.24637147],\n",
       "       [ 0.59405462, -0.07002087],\n",
       "       [-2.03330517, -0.07002087],\n",
       "       [ 0.32458182, -1.24637147],\n",
       "       [ 0.40157405, -1.24637147],\n",
       "       [-1.10939843, -0.07002087],\n",
       "       [ 1.03675993, -1.24637147],\n",
       "       [-0.61857297, -0.07002087],\n",
       "       [ 0.44007016, -0.07002087],\n",
       "       [ 1.14262424, -1.24637147],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 0.45931822,  1.10632974],\n",
       "       [ 1.88367444,  1.10632974],\n",
       "       [ 0.45931822, -1.24637147],\n",
       "       [-0.12774752, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [ 0.85390339, -0.07002087],\n",
       "       [ 0.15134931, -0.07002087],\n",
       "       [ 0.8250313 ,  1.10632974],\n",
       "       [ 0.84427936,  1.10632974],\n",
       "       [-0.64744506, -1.24637147],\n",
       "       [ 1.24848856, -1.24637147],\n",
       "       [ 0.85390339,  1.10632974],\n",
       "       [ 1.69119387,  1.10632974],\n",
       "       [ 1.6334497 ,  1.10632974],\n",
       "       [ 1.46021718, -1.24637147],\n",
       "       [ 1.68156984, -0.07002087],\n",
       "       [-0.02188321,  1.10632974],\n",
       "       [ 0.87315144,  1.10632974],\n",
       "       [-0.33947615, -1.24637147],\n",
       "       [ 1.3639769 ,  1.10632974],\n",
       "       [ 1.12337618, -1.24637147],\n",
       "       [ 1.97029069, -0.07002087]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled = scaler.transform(x)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regression with scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.17181389, -0.00703007]), 3.330238095238095)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_scaled, y)\n",
    "reg.coef_, reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept (bias)</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Features   Weights\n",
       "0  intercept (bias)  3.330238\n",
       "1               SAT  0.171814\n",
       "2        Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary = pd.DataFrame(data=[['intercept (bias)'], ['SAT'], ['Rand 1,2,3']], columns=['Features'])\n",
    "reg_summary['Weights'] = reg.intercept_, reg.coef_[0], reg.coef_[1]\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the standardized coefficients (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT  Rand 1,2,3\n",
       "0  1700           2\n",
       "1  1800           1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame(data=[[1700, 2], [1800, 1]], columns=['SAT', 'Rand 1,2,3'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShayanJul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([295.39979563, 312.58821497])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data)\n",
    "# this results in wrong output because we didn't standardized the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09051403, 3.26413803])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so we should scale our data with the info that already is in scaler\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "reg.predict(new_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting and Overfitting\n",
    "* Overfitting means that our training has focused on the particular training data set so much, it has \"missed the point\"\n",
    "    * The problem is that random noise is captured inside an overfitted model.\n",
    "    * Overfitting is hard to spot because the accuracy of the model seems outstanding.\n",
    "    * The solution is to split the initial dataset into two. training and test\n",
    "        * Because the model has never seen the test data set it can't overfit on it.\n",
    "* Underfitting means that the model has not captured the underlying logic of the data.\n",
    "    * Underfitted models have low accuracy. It means there are no relationships to be found or we need a different model.\n",
    "    * Underfitting is easy to spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing related modules\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100]),\n",
       " array([501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
       "        514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
       "        527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
       "        540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
       "        553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "        566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
       "        579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
       "        592, 593, 594, 595, 596, 597, 598, 599, 600]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating two arrays for splitting the data\n",
    "a = np.arange(1, 101)\n",
    "b = np.arange(501, 601)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "a_train, a_test, b_train, b_test = train_test_split(a, b, test_size=0.2, shuffle=False, random_state=42)\n",
    "# default test size is 25%\n",
    "# shuffle is True by default and in practice, most of the times we want to shuffle the data\n",
    "# Without setting a random_state value we'll get a different subsets each time we split the data\n",
    "# a and b elements are shuffled in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,),\n",
       " (20,),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "        69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]),\n",
       " array([ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "         94,  95,  96,  97,  98,  99, 100]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring the results\n",
    "a_train.shape, a_test.shape, a_train, a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,),\n",
       " (20,),\n",
       " array([501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
       "        514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
       "        527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
       "        540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
       "        553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "        566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
       "        579, 580]),\n",
       " array([581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
       "        594, 595, 596, 597, 598, 599, 600]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train.shape, b_test.shape, b_train, b_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86eebd4e855670ee32c7a6aa21ae179f0342ad5d362a303af33f9d556380de59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
